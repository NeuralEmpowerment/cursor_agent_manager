# ADR-002: Telemetry Storage Solution

**Status**: Accepted  
**Deciders**: Team  
**Date**: 2025-06-18  
**Technical Story**: Storage and analytics system for agent monitoring telemetry data  

## Context and Problem Statement

The Agent Monitor POC requires comprehensive telemetry collection and storage to track detection events, performance metrics, and system analytics. The system needs to store structured event data with efficient querying capabilities for real-time monitoring and historical analysis.

Key requirements include:
- Persistent storage of detection events and metrics
- Support for structured event types (idle detection, active detection, failures)
- Efficient querying for analytics and reporting
- Data retention policies and cleanup mechanisms
- Export capabilities for external analysis
- Minimal operational overhead for a POC application

## Decision Drivers

- **Simplicity**: Minimal setup and configuration requirements
- **Zero external dependencies**: No database server setup required
- **Performance**: Fast read/write operations for real-time monitoring
- **Built-in availability**: Must work on any Python installation
- **Data structure support**: Handle complex event data with metadata
- **Analytics requirements**: Support for time-based queries and aggregations
- **Export capabilities**: CSV and JSON export for external analysis

## Considered Options

1. **SQLite Database** - File-based SQL database with Python built-in support
2. **JSON File Storage** - Simple JSON file with structured event logging
3. **PostgreSQL Database** - Full-featured relational database
4. **In-Memory Storage** - Runtime-only storage with no persistence

## Decision Outcome

**Chosen option**: "SQLite Database"

**Rationale**: SQLite provides the optimal balance of functionality, simplicity, and performance for a POC application. It offers SQL querying capabilities without requiring database server setup, has built-in Python support, and provides ACID compliance for data integrity.

### Positive Consequences
- No external database server required
- Full SQL querying capabilities for complex analytics
- ACID compliance ensures data integrity
- Excellent performance for the expected data volumes
- Built-in backup and export capabilities
- Easy migration path to other databases if needed

### Negative Consequences
- File-based storage may not scale to enterprise levels
- Limited concurrent write capabilities
- No built-in replication or high-availability features

## Pros and Cons of the Options

### SQLite Database

**Description**: Embedded SQL database engine with file-based storage and full SQL support

**Pros**:
- Zero configuration - works out of the box
- Full SQL support for complex queries
- ACID transactions for data integrity
- Excellent performance for read-heavy workloads
- Built-in Python support (sqlite3 module)
- Easy backup (simple file copy)
- Efficient storage with automatic optimization

**Cons**:
- Limited concurrent write performance
- Single file storage (though adequate for POC)
- No network access capabilities

### JSON File Storage

**Description**: Simple append-only JSON file for event logging

**Pros**:
- Extremely simple implementation
- Human-readable format
- Easy debugging and inspection
- No schema dependencies

**Cons**:
- No efficient querying capabilities
- Memory-intensive for large datasets
- No built-in data integrity guarantees
- Difficult analytics and aggregations
- No indexing or optimization

### PostgreSQL Database

**Description**: Full-featured relational database with network capabilities

**Pros**:
- Enterprise-grade features and scalability
- Advanced SQL capabilities
- High concurrent performance
- Built-in replication and backup

**Cons**:
- Requires external database server setup
- Significant operational overhead
- Overkill for POC requirements
- Additional deployment complexity

## Implementation Details

### Technical Approach

The implementation consists of several key components:

1. **Data Models** (`telemetry/models.py`):
   - `DetectionEvent`: Core event structure with timestamps, confidence, state
   - `EventType`: Enum for structured event categorization
   - `TelemetryStats`: Aggregated statistics structure

2. **Repository Pattern** (`telemetry/sqlite_repository.py`):
   - `SqliteRepository`: Clean data access layer
   - Automatic schema creation and migration
   - Configurable data retention policies
   - Efficient querying with indexes

3. **Service Layer** (`telemetry/telemetry_service.py`):
   - `TelemetryService`: Business logic for event recording
   - Statistics calculation and aggregation
   - Event filtering and querying APIs

4. **Analytics Engine** (`telemetry/analytics.py`):
   - Time-based analytics (hourly, daily, custom ranges)
   - Data export capabilities (CSV, JSON)
   - Statistical calculations and reporting

### Database Schema

```sql
CREATE TABLE detection_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    timestamp REAL NOT NULL,
    event_type TEXT NOT NULL,
    state TEXT,
    confidence REAL,
    detection_method TEXT,
    message TEXT,
    match_rect TEXT,
    metadata TEXT
);

CREATE INDEX idx_detection_events_timestamp ON detection_events(timestamp);
CREATE INDEX idx_detection_events_type ON detection_events(event_type);
CREATE INDEX idx_detection_events_state ON detection_events(state);
```

### Migration Strategy

The system automatically handles schema creation and migration:
- Database file created on first run
- Schema versioning for future migrations
- Backward compatibility maintenance

### Timeline

- **Phase 1** (Completed): Core SQLite repository implementation
- **Phase 2** (Completed): Service layer and business logic
- **Phase 3** (Completed): Analytics engine and export capabilities
- **Phase 4** (Completed): CLI tools for data analysis

## Validation

### Success Criteria
- Event recording latency < 10ms
- Support for 1000+ events per hour
- Query response time < 100ms for analytics
- Successful CSV/JSON export functionality
- Automatic data retention and cleanup

### Testing Strategy
- Unit tests for repository operations
- Integration tests for service layer
- Performance benchmarks for high-volume scenarios
- Data integrity validation tests
- Export functionality verification

### Monitoring
- Database file size monitoring
- Query performance metrics
- Event recording success rates
- Storage cleanup effectiveness

## Links and References

- [SQLite Documentation](https://sqlite.org/docs.html)
- [Python sqlite3 Module](https://docs.python.org/3/library/sqlite3.html)
- [Repository Pattern](https://martinfowler.com/eaaCatalog/repository.html)

### Related ADRs
- [ADR-001](ADR-001.md): Detection Engine Architecture - Related for confidence logging
- [ADR-006](ADR-006.md): Dependency Injection Pattern - Related for service management

### Related Documentation
- [Telemetry README](../../TELEMETRY_README.md) - Detailed system documentation
- [Analytics CLI](../../analytics_cli.py) - Command-line analytics tools

## Change History

| Date | Author | Change Description |
|------|--------|-------------------|
| 2025-06-18 | Team | Initial creation based on implemented SQLite system |

## Notes

The SQLite implementation has proven highly effective for the POC requirements, handling real-time event recording with excellent performance. The file-based approach simplifies deployment and backup procedures while providing full SQL capabilities for complex analytics queries. The automatic retention policies ensure the database remains manageable over time. 